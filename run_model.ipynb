{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import tempfile\n",
    "import fiona\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import traceback\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# warning messages\n",
    "message = {}\n",
    "\n",
    "# get the shapefile folder\n",
    "shapefile_folder = os.path.join(cwd, 'shapefile')\n",
    "# Pattern to match shapefile (shapefile typically have extensions like .shp)\n",
    "shapefile_pattern = os.path.join(shapefile_folder, '*.shp')\n",
    "\n",
    "shapefiles_list = glob.glob(shapefile_pattern)\n",
    "# print(shapefiles_list)\n",
    "\n",
    "# Count the number of shapefile\n",
    "num_shapefiles = len(shapefiles_list)\n",
    "# print(num_shapefiles)\n",
    "\n",
    "# get the java folder\n",
    "java_folder = os.path.join(cwd, 'source/java')\n",
    "\n",
    "# get the csv folder\n",
    "csv_folder = os.path.join(cwd, 'source/csv_files')\n",
    "# Ensure the output directory exists and remove all existing CSV files in the output folder\n",
    "if os.path.exists(csv_folder):\n",
    "    for file in glob.glob(os.path.join(csv_folder, '*.csv')):\n",
    "        os.remove(file)\n",
    "    else:\n",
    "        os.makedirs(csv_folder, exist_ok=True)\n",
    "# get the modified csv folder path\n",
    "modified_csv_folder = os.path.join(cwd, 'source/modified_csv_for_curr_QMD')\n",
    "if os.path.exists(modified_csv_folder):\n",
    "        for file in glob.glob(os.path.join(modified_csv_folder, '*.csv')):\n",
    "            os.remove(file)\n",
    "        else:\n",
    "            os.makedirs(modified_csv_folder, exist_ok=True)\n",
    "result_folder = os.path.join(cwd, 'result')\n",
    "if os.path.exists(result_folder):\n",
    "        for file in glob.glob(os.path.join(result_folder, '*.csv')):\n",
    "            os.remove(file)\n",
    "        else:\n",
    "            os.makedirs(result_folder, exist_ok=True)\n",
    "# get the raster file\n",
    "raster_folder = os.path.join(cwd,'source/rasters')\n",
    "tiffile = os.path.join(raster_folder,'Final_comp31024.tif')\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_standID_for_generatingCSV_for_CurrQMD(lis):\n",
    "    dic_for_standID_with_currQMD = {}\n",
    "    for item in lis:\n",
    "        if 'curr_QMD' in item and 'curr_TPA' in item:\n",
    "            try:\n",
    "                # Convert the values to floats\n",
    "                curr_qmd = float(item['curr_QMD'][0])\n",
    "                curr_tpa = float(item['curr_TPA'][0])\n",
    "                # Check if the values are not NaN and not zero\n",
    "                if not np.isnan(curr_qmd) and not np.isnan(curr_tpa) and curr_qmd != 0 and curr_tpa != 0:\n",
    "                    stand_id = int(item['StandID'][0])\n",
    "                    dic_for_standID_with_currQMD[stand_id] = [int(item['curr_QMD'][0]),int(item['curr_TPA'][0])]\n",
    "            except (ValueError, TypeError):\n",
    "                print(\"absence due to invalid values\")\n",
    "    return dic_for_standID_with_currQMD\n",
    "\n",
    "        \n",
    "# dic = filter_standID_for_generatingCSV_for_CurrQMD(fields_from_shapefile)\n",
    "# print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(out_image, csv_folder, index, parameters, csv_files, stand_id ,dict_for_standIDnCrrnQMD_from_allFields, csv_with_modified_qmd):\n",
    "        \"\"\"\n",
    "        Process the raster file and save the band data to CSV files for each shape.\n",
    "\n",
    "        Parameters:\n",
    "        - out_image (numpy array): Masked raster data.\n",
    "        - model_parameters (dict): Dictionary containing shape parameters.\n",
    "        - output_folder (str): Folder to save the CSV files.\n",
    "        Returns:\n",
    "        - List of CSV filenames.\n",
    "        \"\"\"     \n",
    "        os.makedirs(csv_folder, exist_ok=True)\n",
    "        # column_names = ['aws0_100', 'DEP2RES', 'HeatLoad', 'MAPMCMT', 'Rad_sm', 'B_TD', 'soc_05','soc0_20','slope','pratio','consLITH']\n",
    "        column_names = [ 'USA_Slope', 'HeatLoad','Cons_LITH', 'Rad_sm', 'B_TD', 'MCMT', 'MAP', 'PRATIO', 'DEP2RES','aws0_100', 'soc0_5']\n",
    "\n",
    "        with rasterio.open(tiffile) as src:\n",
    "            # Flatten band data and create DataFrame\n",
    "            band_data = {f'band_{j+1}': out_image[j].flatten() for j in range(out_image.shape[0])}\n",
    "            df = pd.DataFrame(band_data)\n",
    "            # Replace the nodata values with NaN\n",
    "            for band in band_data:\n",
    "                df[band] = df[band].replace(src.nodata, np.nan)\n",
    "            df_cleaned = df    \n",
    "            if not df_cleaned.empty:\n",
    "                # Rename columns\n",
    "                if len(column_names) >= df_cleaned.shape[1]:\n",
    "                    df_cleaned.columns = column_names[:df_cleaned.shape[1]]\n",
    "                # Extend the csv file with the model parameters\n",
    "                param_df = pd.DataFrame({key: [value[0]] * len(df_cleaned) for key, value in parameters.items()})\n",
    "                param_df = param_df.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "                df_extended = pd.concat([df_cleaned, param_df], axis=1)\n",
    "                value_mapping = {\n",
    "                    1: 'Extrusive',\n",
    "                    2: 'Other',\n",
    "                    3: 'Sedimentary',\n",
    "                    4: 'Unconsolidated-Fine',\n",
    "                    5: 'Metasedimentary',\n",
    "                    6: 'CaSedimentary',\n",
    "                    7: 'Unconsolidated-Coarse',\n",
    "                    8: 'Plutonic',\n",
    "                    9: 'Metamorphic',\n",
    "                    10: 'Unconsolidated-Organic',\n",
    "                    11: 'CaMetasedimentary',\n",
    "                    12: 'Unconsolidated'\n",
    "                }\n",
    "                # Replace the numeric values with string values\n",
    "                df_extended['Cons_LITH'] = df_extended['Cons_LITH'].replace(value_mapping)\n",
    "                df_extended['MCMT'] = df_extended['MCMT'] /10\n",
    "                df_extended['PRATIO'] = df_extended['PRATIO']/10000\n",
    "                # drop the NaN values\n",
    "                df_extended = df_extended.dropna()\n",
    "                # Save to CSV\n",
    "                csv_filename = f\"csv_for_stand_{stand_id}.csv\"\n",
    "                csv_path = os.path.join(csv_folder, csv_filename)\n",
    "                csv_files.append(csv_path)\n",
    "                df_extended.to_csv(csv_path, index=False)\n",
    "                if stand_id in dict_for_standIDnCrrnQMD_from_allFields:\n",
    "                     Current_QMD =  dict_for_standIDnCrrnQMD_from_allFields[stand_id]\n",
    "                     print(Current_QMD)\n",
    "                     df_extended['QMD'] = Current_QMD[0]\n",
    "                     new_file_name = f\"with_cur_QMD_{csv_filename}\"\n",
    "                     csv_with_modified_qmd.append(os.path.join(modified_csv_folder, new_file_name))\n",
    "                     df_extended.to_csv(os.path.join(modified_csv_folder, new_file_name), index=False)\n",
    "\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 700]\n",
      "[11, 400]\n",
      "[12, 390]\n",
      "[9, 550]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# csvfile list\n",
    "csv_files = []\n",
    "# Define desired columns\n",
    "desired_columns = ['QMD', 'RC_PROP', 'WH_PROP', 'GF_PROP', 'LP_PROP', 'WL_PROP', 'DF_PROP', 'PP_PROP']\n",
    "stand_id = []\n",
    "fields_from_shapefile = []\n",
    "dict_for_standIDnCrrnQMD_from_allFields = {}\n",
    "csv_with_current_qmd_and_tpa = []\n",
    "\n",
    "\n",
    "for shapefile in shapefiles_list:\n",
    "    # Path to your shapefile\n",
    "    shapefile_path = shapefile\n",
    "    # Read the main shapefile\n",
    "    try:\n",
    "        ply = gpd.read_file(shapefile_path)\n",
    "    except Exception as ex:\n",
    "        print(f\"Unable to read shapefile  {shapefile_path}. Your file may be corrupt: {ex}\")\n",
    "        raise\n",
    "\n",
    "    # Change CRS to match raster\n",
    "    ply = ply.to_crs(epsg=3857)\n",
    "    with tempfile.NamedTemporaryFile() as tf:\n",
    "        crsName = tf.name\n",
    "    ply.to_file(crsName)  # Write new shapefile \n",
    "    # Read and process shapefile\n",
    "    with rasterio.open(tiffile) as geotiff:\n",
    "        with fiona.open(crsName, \"r\") as shapefile:\n",
    "            shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "            for index, shape in enumerate(shapes):\n",
    "                try:\n",
    "                    out_image, out_transform = rasterio.mask.mask(geotiff, [shape], crop=True, all_touched=True)                 \n",
    "                    # Extract desired columns from the clipped shapefile\n",
    "                    clipped_shapefile = ply.clip(gpd.GeoDataFrame(geometry=[shape], crs=ply.crs))\n",
    "                    fields_from_shapefile.append(clipped_shapefile.copy().to_dict(orient='list'))\n",
    "                    dict_for_standIDnCrrnQMD_from_allFields = filter_standID_for_generatingCSV_for_CurrQMD(fields_from_shapefile)\n",
    "                    extracted_data = clipped_shapefile[desired_columns].copy()\n",
    "                    extracted_data[\"W_ShadeTol\"] = extracted_data[\"RC_PROP\"] * 4.73 + extracted_data[\"WH_PROP\"] * 4.96 + extracted_data[\"GF_PROP\"] * 4.01 + extracted_data[\"LP_PROP\"] * 1.73 + extracted_data[\"WL_PROP\"] * 1.35 + extracted_data[\"DF_PROP\"] * 2.78 + extracted_data[\"PP_PROP\"] * 1.64\n",
    "                    extracted_data[\"W_DroughtTol\"] = extracted_data[\"RC_PROP\"] * 2.23 + extracted_data[\"WH_PROP\"] * 1.17 + extracted_data[\"GF_PROP\"] * 2.33 + extracted_data[\"LP_PROP\"] * 4.04 + extracted_data[\"WL_PROP\"] * 2.42 + extracted_data[\"DF_PROP\"] * 2.62 + extracted_data[\"PP_PROP\"] * 4.32                 \n",
    "                    # Extract StandID as integer and append to stand_id list -- we are getting this stand id from shapefile \n",
    "                    stand_id_value = int(clipped_shapefile['StandID'].values[0])\n",
    "                    stand_id.append(stand_id_value)                  \n",
    "                    # Convert the extracted data to a dictionary\n",
    "                    extracted_data_dict_list = extracted_data.to_dict(orient='records')\n",
    "                    # convert the list of dictionaries into a single dictionary \n",
    "                    extracted_data_dict = extracted_data.to_dict(orient='list')\n",
    "                    # fields_from_shapefile.append(extracted_data_dict)\n",
    "                    # Call to_csv function to create and save the CSV file\n",
    "                    to_csv(out_image, csv_folder, index, extracted_data_dict, csv_files, stand_id[-1], dict_for_standIDnCrrnQMD_from_allFields, csv_with_current_qmd_and_tpa)\n",
    "                except Exception as ex:\n",
    "                    print(f\"Error processing shape {index}: {str(ex)}\")\n",
    "                    traceback.print_exc()  # Print the full traceback\n",
    "                    print(\"\\n\")\n",
    "                    print(\"\\n\")\n",
    "                    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Id': [0], 'StandID': [11.0], 'QMD': [10.0], 'RC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'LP_PROP': [0.0], 'WL_PROP': [0.0], 'DF_PROP': [1.0], 'PP_PROP': [0.0], 'curr_QMD': [8.0], 'curr_TPA': [700.0], 'geometry': [<POLYGON ((-12890060.839 5978042.574, -12880693.712 5935692.332, -12912794.7...>]}, {'Id': [0], 'StandID': [22.0], 'QMD': [10.0], 'RC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'LP_PROP': [0.0], 'WL_PROP': [0.0], 'DF_PROP': [1.0], 'PP_PROP': [0.0], 'curr_QMD': [11.0], 'curr_TPA': [400.0], 'geometry': [<POLYGON ((-13331829.383 6245403.014, -13294934.123 6194934.622, -13330251.0...>]}, {'Id': [0], 'StandID': [55.0], 'QMD': [10.0], 'RC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'LP_PROP': [0.0], 'WL_PROP': [0.0], 'DF_PROP': [1.0], 'PP_PROP': [0.0], 'curr_QMD': [12.0], 'curr_TPA': [390.0], 'geometry': [<POLYGON ((-13002510.161 6232920.48, -13020317.891 6190275.082, -13033981.56...>]}, {'Id': [0], 'StandID': [66.0], 'QMD': [10.0], 'RC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'LP_PROP': [0.0], 'WL_PROP': [0.0], 'DF_PROP': [1.0], 'PP_PROP': [0.0], 'curr_QMD': [9.0], 'curr_TPA': [550.0], 'geometry': [<POLYGON ((-13544686.742 5233479.963, -13548794.982 5227784.233, -13554649.0...>]}, {'Id': [0], 'StandID': [111.0], 'QMD': [10.0], 'RC_PROP': [0.0], 'WH_PROP': [0.1], 'GF_PROP': [0.0], 'LP_PROP': [0.0], 'WL_PROP': [0.0], 'DF_PROP': [0.9], 'PP_PROP': [0.0], 'geometry': [<POLYGON ((-12827004.361 5988787.513, -12838262.92 5953376.83, -12867496.896...>]}, {'Id': [0], 'StandID': [222.0], 'QMD': [10.0], 'RC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'LP_PROP': [0.0], 'WL_PROP': [0.0], 'DF_PROP': [1.0], 'PP_PROP': [0.0], 'geometry': [<POLYGON ((-13303466.491 6180356.576, -13322705.083 6172964.549, -13323157.5...>]}, {'Id': [0], 'StandID': [555.0], 'QMD': [10.0], 'RC_PROP': [0.7], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'LP_PROP': [0.0], 'WL_PROP': [0.0], 'DF_PROP': [0.3], 'PP_PROP': [0.0], 'geometry': [<POLYGON ((-12921222.207 6213540.993, -12961042.742 6171021.803, -12961583.9...>]}, {'Id': [0], 'StandID': [666.0], 'QMD': [10.0], 'RC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.5], 'LP_PROP': [0.0], 'WL_PROP': [0.0], 'DF_PROP': [0.5], 'PP_PROP': [0.0], 'geometry': [<POLYGON ((-13496807.452 5252017.034, -13516797.539 5247024.753, -13523830.3...>]}]\n"
     ]
    }
   ],
   "source": [
    "print(fields_from_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\trails\\\\testing model with %sdimax\\\\INLAND MODEL\\\\source/csv_files\\\\csv_for_stand_11.csv', 'd:\\\\trails\\\\testing model with %sdimax\\\\INLAND MODEL\\\\source/csv_files\\\\csv_for_stand_22.csv', 'd:\\\\trails\\\\testing model with %sdimax\\\\INLAND MODEL\\\\source/csv_files\\\\csv_for_stand_55.csv', 'd:\\\\trails\\\\testing model with %sdimax\\\\INLAND MODEL\\\\source/csv_files\\\\csv_for_stand_66.csv', 'd:\\\\trails\\\\testing model with %sdimax\\\\INLAND MODEL\\\\source/csv_files\\\\csv_for_stand_111.csv', 'd:\\\\trails\\\\testing model with %sdimax\\\\INLAND MODEL\\\\source/csv_files\\\\csv_for_stand_222.csv', 'd:\\\\trails\\\\testing model with %sdimax\\\\INLAND MODEL\\\\source/csv_files\\\\csv_for_stand_555.csv', 'd:\\\\trails\\\\testing model with %sdimax\\\\INLAND MODEL\\\\source/csv_files\\\\csv_for_stand_666.csv'] ['11', '22', '55', '66', '111', '222', '555', '666']\n"
     ]
    }
   ],
   "source": [
    "# this code will filter out the csv that are not empty and can be fed to model.\n",
    "\n",
    "def filter_csv(folder_path):\n",
    "    # List all CSV files in the folder\n",
    "    csv_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    if csv_files is None:\n",
    "        return \n",
    "    # Initialize a list to store the 'stand' values from non-empty CSV files\n",
    "    stand_id_result = []\n",
    "    csv_for_result = []\n",
    "    # Check each CSV file\n",
    "    for files in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(files)  # Read the CSV file into a DataFrame\n",
    "            if not df.empty:  # If the CSV file is not empty\n",
    "                # Extract the 'stand' value from the file name\n",
    "                csv_for_result.append(files)\n",
    "                filename = os.path.basename(files)  # Get the file name without the path\n",
    "                stand = filename.split('_')[-1].split('.')[0]  # Extract the 'stand' part\n",
    "                stand_id_result.append(stand)  # Add the 'stand' to the list\n",
    "        except pd.errors.EmptyDataError:\n",
    "            # Handle the case where the CSV file is empty or invalid\n",
    "            print(f\"{file} is empty or has no valid data.\")\n",
    "    return csv_for_result, stand_id_result\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(csv_for_result):\n",
    "    predictions_and_stats_list = []\n",
    "    # Navigate to the 'java' directory (adjust path as needed)\n",
    "    cwd = os.getcwd()  # Assuming cwd is defined somewhere earlier\n",
    "    JAVA_SERVICE_PATH = os.path.join(cwd, 'source/java')\n",
    "    H2O_GENMODEL_JAR_PATH = os.path.join(JAVA_SERVICE_PATH, 'h2o-genmodel.jar')\n",
    "    GSON_JAR_PATH = os.path.join(JAVA_SERVICE_PATH, 'gson-2.8.8.jar')\n",
    "    MAIN_JAVA_FILE_PATH = os.path.join(JAVA_SERVICE_PATH, 'main1.java')\n",
    "\n",
    "    # Check if Java files and JARs exist\n",
    "    if not os.path.exists(H2O_GENMODEL_JAR_PATH):\n",
    "        raise FileNotFoundError(f\"JAR file not found: {H2O_GENMODEL_JAR_PATH}\")\n",
    "    if not os.path.exists(GSON_JAR_PATH):\n",
    "        raise FileNotFoundError(f\"JAR file not found: {GSON_JAR_PATH}\")\n",
    "    if not os.path.exists(MAIN_JAVA_FILE_PATH):\n",
    "        raise FileNotFoundError(f\"Java file not found: {MAIN_JAVA_FILE_PATH}\")\n",
    "\n",
    "    # Use the correct classpath separator\n",
    "    classpath_separator = os.pathsep\n",
    "    classpath = f'.{classpath_separator}{H2O_GENMODEL_JAR_PATH}{classpath_separator}{GSON_JAR_PATH}'\n",
    "\n",
    "    try:\n",
    "        for item in csv_for_result:\n",
    "            # Compile the Java code\n",
    "            compile_command = ['javac', '-cp', classpath, 'main1.java']\n",
    "            subprocess.run(compile_command, cwd=JAVA_SERVICE_PATH, check=True)\n",
    "            # Execute the Java code and capture the output\n",
    "            run_command = ['java', '-cp', classpath, 'main1', item]\n",
    "            output = subprocess.check_output(run_command, cwd=JAVA_SERVICE_PATH)\n",
    "            output_str = output.decode('utf-8')\n",
    "            # Process the output (assuming it's JSON)\n",
    "            predictions_and_stats = json.loads(output_str)\n",
    "            # Round statistical metrics to the nearest integer\n",
    "            rounded_predictions = {metric: round(value) for metric, value in predictions_and_stats.items()}\n",
    "            predictions_and_stats_list.append(rounded_predictions)\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error executing Java code: {e}\")\n",
    "        raise RuntimeError('Error executing Java code') from e  # Handle error as needed\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON output from Java: {e}\")\n",
    "        raise RuntimeError('Error decoding JSON output from Java') from e  # Handle JSON decoding error\n",
    "    return predictions_and_stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path\n",
    "folder_path = os.path.join(os.getcwd(), \"source/csv_files\")\n",
    "csv_for_result, stand_id_result = filter_csv(folder_path)\n",
    "\n",
    "print(csv_for_result, stand_id_result)\n",
    "predictions_and_stats_list = prediction(csv_for_result)\n",
    "df = pd.DataFrame(predictions_and_stats_list)\n",
    "df['StandId'] = [items for items in stand_id_result]\n",
    "\n",
    "# Move 'StandId' to the first column\n",
    "cols = ['StandId'] + [col for col in df.columns if col != 'StandId']\n",
    "df = df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StandId</th>\n",
       "      <th>mode</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>highestValue</th>\n",
       "      <th>lowestValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>523</td>\n",
       "      <td>503</td>\n",
       "      <td>494</td>\n",
       "      <td>578</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>327</td>\n",
       "      <td>352</td>\n",
       "      <td>357</td>\n",
       "      <td>421</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>437</td>\n",
       "      <td>417</td>\n",
       "      <td>424</td>\n",
       "      <td>525</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>407</td>\n",
       "      <td>422</td>\n",
       "      <td>419</td>\n",
       "      <td>449</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>510</td>\n",
       "      <td>542</td>\n",
       "      <td>543</td>\n",
       "      <td>590</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>222</td>\n",
       "      <td>327</td>\n",
       "      <td>332</td>\n",
       "      <td>338</td>\n",
       "      <td>393</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>555</td>\n",
       "      <td>431</td>\n",
       "      <td>485</td>\n",
       "      <td>486</td>\n",
       "      <td>582</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>666</td>\n",
       "      <td>448</td>\n",
       "      <td>448</td>\n",
       "      <td>447</td>\n",
       "      <td>487</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StandId  mode  median  mean  highestValue  lowestValue\n",
       "0      11   523     503   494           578          362\n",
       "1      22   327     352   357           421          326\n",
       "2      55   437     417   424           525          368\n",
       "3      66   407     422   419           449          388\n",
       "4     111   510     542   543           590          473\n",
       "5     222   327     332   338           393          326\n",
       "6     555   431     485   486           582          402\n",
       "7     666   448     448   447           487          437"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stats with current TPA and current SDImax'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StandId</th>\n",
       "      <th>Curr_SDImax</th>\n",
       "      <th>Curr_QMD</th>\n",
       "      <th>Curr_TPA</th>\n",
       "      <th>%SDImax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>689</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>101.596517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>295</td>\n",
       "      <td>11</td>\n",
       "      <td>400</td>\n",
       "      <td>135.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>297</td>\n",
       "      <td>12</td>\n",
       "      <td>390</td>\n",
       "      <td>131.313131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>508</td>\n",
       "      <td>9</td>\n",
       "      <td>550</td>\n",
       "      <td>108.267717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StandId  Curr_SDImax  Curr_QMD  Curr_TPA     %SDImax\n",
       "0      11          689         8       700  101.596517\n",
       "1      22          295        11       400  135.593220\n",
       "2      55          297        12       390  131.313131\n",
       "3      66          508         9       550  108.267717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Folder path\n",
    "folder_path = modified_csv_folder\n",
    "csv_for_result, stand_id_result = filter_csv(folder_path)\n",
    "# print(csv_for_result)\n",
    "df2=None\n",
    "if csv_for_result != [] and stand_id_result != []:\n",
    "    predictions_and_stats_list = prediction(csv_for_result)\n",
    "    df2 = pd.DataFrame(predictions_and_stats_list)\n",
    "    df2['StandId'] = [items for items in stand_id_result]\n",
    "    df2['Curr_QMD'] = [int(values[0]) for item, values in dict_for_standIDnCrrnQMD_from_allFields.items()]\n",
    "    df2['Curr_TPA'] = [int(values[1]) for item, values in dict_for_standIDnCrrnQMD_from_allFields.items()]\n",
    "    # Move 'StandId' to the first column\n",
    "    cols = ['StandId'] + [col for col in df2.columns if col != 'StandId']\n",
    "    df2 = df2[['StandId','median', 'Curr_QMD','Curr_TPA' ]]\n",
    "    df2 = df2.rename(columns={'median': 'Curr_SDImax'})\n",
    "    df2['%SDImax'] =  (df2['Curr_TPA'] * 100 )/ df2['Curr_SDImax']\n",
    "    display(\"stats with current TPA and current SDImax\")\n",
    "    display(df2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StandId</th>\n",
       "      <th>mode</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>highestValue</th>\n",
       "      <th>lowestValue</th>\n",
       "      <th>Curr_SDImax</th>\n",
       "      <th>Curr_QMD</th>\n",
       "      <th>Curr_TPA</th>\n",
       "      <th>%SDImax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>523</td>\n",
       "      <td>503</td>\n",
       "      <td>494</td>\n",
       "      <td>578</td>\n",
       "      <td>362</td>\n",
       "      <td>689.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>101.596517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>510</td>\n",
       "      <td>542</td>\n",
       "      <td>543</td>\n",
       "      <td>590</td>\n",
       "      <td>473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>327</td>\n",
       "      <td>352</td>\n",
       "      <td>357</td>\n",
       "      <td>421</td>\n",
       "      <td>326</td>\n",
       "      <td>295.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>135.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>327</td>\n",
       "      <td>332</td>\n",
       "      <td>338</td>\n",
       "      <td>393</td>\n",
       "      <td>326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>437</td>\n",
       "      <td>417</td>\n",
       "      <td>424</td>\n",
       "      <td>525</td>\n",
       "      <td>368</td>\n",
       "      <td>297.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>131.313131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>555</td>\n",
       "      <td>431</td>\n",
       "      <td>485</td>\n",
       "      <td>486</td>\n",
       "      <td>582</td>\n",
       "      <td>402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66</td>\n",
       "      <td>407</td>\n",
       "      <td>422</td>\n",
       "      <td>419</td>\n",
       "      <td>449</td>\n",
       "      <td>388</td>\n",
       "      <td>508.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>108.267717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>666</td>\n",
       "      <td>448</td>\n",
       "      <td>448</td>\n",
       "      <td>447</td>\n",
       "      <td>487</td>\n",
       "      <td>437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StandId  mode  median  mean  highestValue  lowestValue  Curr_SDImax  \\\n",
       "0      11   523     503   494           578          362        689.0   \n",
       "1     111   510     542   543           590          473          NaN   \n",
       "2      22   327     352   357           421          326        295.0   \n",
       "3     222   327     332   338           393          326          NaN   \n",
       "4      55   437     417   424           525          368        297.0   \n",
       "5     555   431     485   486           582          402          NaN   \n",
       "6      66   407     422   419           449          388        508.0   \n",
       "7     666   448     448   447           487          437          NaN   \n",
       "\n",
       "   Curr_QMD  Curr_TPA     %SDImax  \n",
       "0       8.0     700.0  101.596517  \n",
       "1       NaN       NaN         NaN  \n",
       "2      11.0     400.0  135.593220  \n",
       "3       NaN       NaN         NaN  \n",
       "4      12.0     390.0  131.313131  \n",
       "5       NaN       NaN         NaN  \n",
       "6       9.0     550.0  108.267717  \n",
       "7       NaN       NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if df2 is not None:\n",
    "    merged_df = pd.merge(df, df2, how='outer', on='StandId')\n",
    "    merged_df = merged_df.rename(columns={'Curr_SDImax_x': 'median', 'Curr_SDImax_y': 'Curr_SDImax'})\n",
    "    display(merged_df)  \n",
    "    result_folder = os.path.join(cwd,'result/result_with_current_QMD_and_TPA.csv')\n",
    "    df.to_csv(result_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = os.path.join(cwd,'result/result.csv')\n",
    "df.to_csv(result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
